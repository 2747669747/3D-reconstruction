http://blog.csdn.net/aichipmunk/article/details/8721290
vs  https://jingyan.baidu.com/article/37bce2be6e58801002f3a2b2.html
http://blog.csdn.net/u012200908/article/details/44462025
kinect1三维重建环境配置
http://blog.csdn.net/eddy_zheng/article/details/49976005
https://jingyan.baidu.com/article/ab0b5630aa6fcfc15afa7d1f.html
http://blog.csdn.net/insaneguy/article/details/37881283
kinect1读取深度图像数据c++程序

**
http://blog.csdn.net/kh1445291129/article/details/37879119
opencv_core249d.lib
opencv_gpu249d.lib
opencv_highgui249d.lib
Kinect10.lib
opencv_calib3d249d.lib
opencv_flann249d.lib
opencv_legacy249d.lib
opencv_objdetect249d.lib
opencv_ts249d.lib
opencv_contrib249d.lib
opencv_nonfree249d.lib
opencv_features2d249d.lib
opencv_imgproc249d.lib
opencv_ml249d.lib
opencv_ocl249d.lib
opencv_superres249d.lib
opencv_video249d.lib
opencv_videostab249d.lib
opencv_photo249d.lib
opencv_stitching249d.lib
kernel32.lib
user32.lib
gdi32.lib
winspool.lib
comdlg32.lib
advapi32.lib
shell32.lib
ole32.lib
oleaut32.lib
uuid.lib
odbc32.lib
odbccp32.lib
Google kinect1 vs2013 opencv
http://blog.csdn.net/chenkent888/article/details/17137127
**/
http://blog.csdn.net/zouxy09/article/details/8146719
深度图像提取

#include <opencv2\opencv.hpp>  
#include<iostream>
//windows的头文件，必须要，不然NuiApi.h用不了
#include <Windows.h>
//Kinect for windows 的头文件
#include "NuiApi.h"
#include<fstream>

using namespace std;
using namespace cv;

#include <d3d11.h>

double getPSNR(Mat& src1, Mat& src2, int bb)
{
	int i, j;
	double sse, mse, psnr;
	sse = 0.0;

	Mat s1, s2;
	cvtColor(src1, s1, CV_BGR2GRAY);
	cvtColor(src2, s2, CV_BGR2GRAY);

	int count = 0;
	for (j = bb; j<s1.rows - bb; j++)
	{
		uchar* d = s1.ptr(j);
		uchar* s = s2.ptr(j);

		for (i = bb; i<s1.cols - bb; i++)
		{
			sse += ((d[i] - s[i])*(d[i] - s[i]));
			count++;
		}
	}
	if (sse == 0.0 || count == 0)
	{
		return 0;
	}
	else
	{
		mse = sse / (double)(count);
		psnr = 10.0*log10((255 * 255) / mse);
		return psnr;
	}
}
//最远距离(mm)
const int MAX_DISTANCE = 3500;
//最近距离(mm)
const int MIN_DISTANCE = 200;

const LONG m_depthWidth = 640;
const LONG m_depthHeight = 480;
const LONG m_colorWidth = 640;
const LONG m_colorHeight = 480;
const LONG cBytesPerPixel = 4;

int main()
{
	ofstream SaveFile1("data_rgb.txt");
	ofstream SaveFile2("data_depth.txt");
	//彩色图像
	Mat image_rgb;
	//深度图像
	Mat image_depth;

	//创建一个MAT
	image_rgb.create(480, 640, CV_8UC3);
	image_depth.create(480, 640, CV_8UC1);

	//一个KINECT实例指针
	INuiSensor*  m_pNuiSensor = NULL;

	if (m_pNuiSensor != NULL)
	{
		return 0;
	}

	//记录当前连接KINECT的数量（为多连接做准备）
	int iSensorCount;
	//获得当前KINECT的数量
	HRESULT hr = NuiGetSensorCount(&iSensorCount);


	//按照序列初始化KINETC实例，这里就连接了一个KINECT，所以没有用到循环
	hr = NuiCreateSensorByIndex(iSensorCount - 1, &m_pNuiSensor);
	//初始化，让其可以接收彩色和深度数据流
	hr = m_pNuiSensor->NuiInitialize(NUI_INITIALIZE_FLAG_USES_COLOR | NUI_INITIALIZE_FLAG_USES_DEPTH);

	//判断是否出错
	if (FAILED(hr))
	{
		cout << "NuiInitialize failed" << endl;
		return hr;
	}

	//彩色图像获取下一帧事件
	HANDLE nextColorFrameEvent = CreateEvent(NULL, TRUE, FALSE, NULL);
	//彩色图像事件句柄
	HANDLE colorStreamHandle = NULL;
	//深度图像获取下一帧事件
	HANDLE nextDepthFrameEvent = CreateEvent(NULL, TRUE, FALSE, NULL);
	//深度图像事件句柄
	HANDLE depthStreamHandle = NULL;

	//实例打开数据流，这里NUI_IMAGE_TYPE_COLOR表示彩色图像
	hr = m_pNuiSensor->NuiImageStreamOpen(NUI_IMAGE_TYPE_COLOR, NUI_IMAGE_RESOLUTION_640x480, 0, 2, nextColorFrameEvent, &colorStreamHandle);

	if (FAILED(hr))//判断是否提取正确
	{
		cout << "Could not open color image stream video" << endl;
		m_pNuiSensor->NuiShutdown();
		return hr;
	}

	//实例打开数据流，这里NUI_IMAGE_TYPE_DEPTH表示深度图像
	hr = m_pNuiSensor->NuiImageStreamOpen(NUI_IMAGE_TYPE_DEPTH, NUI_IMAGE_RESOLUTION_640x480, 0, 2, nextDepthFrameEvent, &depthStreamHandle);

	if (FAILED(hr))//判断是否提取正确
	{
		cout << "Could not open color image stream video" << endl;
		m_pNuiSensor->NuiShutdown();
		return hr;
	}



	cv::namedWindow("depth", CV_WINDOW_AUTOSIZE);
	moveWindow("depth", 300, 600);
	cv::namedWindow("colorImage", CV_WINDOW_AUTOSIZE);
	moveWindow("colorImage", 0, 200);

	while (1)
	{
		NUI_IMAGE_FRAME pImageFrame_rgb;
		NUI_IMAGE_FRAME pImageFrame_depth;
		//无限等待新的彩色数据，等到后返回
		if (WaitForSingleObject(nextColorFrameEvent, 0) == 0)
		{
			//从刚才打开数据流的流句柄中得到该帧数据，读取到的数据地址存于pImageFrame
			hr = m_pNuiSensor->NuiImageStreamGetNextFrame(colorStreamHandle, 0, &pImageFrame_rgb);
			if (FAILED(hr))
			{
				cout << "Could not get color image" << endl;
				m_pNuiSensor->NuiShutdown();
				return -1;
			}

			INuiFrameTexture *pTexture = pImageFrame_rgb.pFrameTexture;
			NUI_LOCKED_RECT lockedRect;

			//提取数据帧到LockedRect，它包括两个数据对象：pitch每行字节数，pBits第一个字节地址
			//并锁定数据，这样当我们读数据的时候，kinect就不会去修改它


			pTexture->LockRect(0, &lockedRect, NULL, 0);
			//确认获得的数据是否有效
			if (lockedRect.Pitch != 0)
			{
				//将数据转换为OpenCV的Mat格式
				for (int i = 0; i < image_rgb.rows; i++)
				{
					//第i行的指针
					uchar *prt = image_rgb.ptr(i);

					//每个字节代表一个颜色信息，直接使用uchar
					uchar *pBuffer = (uchar*)(lockedRect.pBits) + i * lockedRect.Pitch;
					for (int j = 0; j < image_rgb.cols; j++)
					{
						prt[3 * j] = pBuffer[4 * j];//内部数据是4个字节，0-1-2是BGR，第4个现在未使用
						prt[3 * j + 1] = pBuffer[4 * j + 1];
						prt[3 * j + 2] = pBuffer[4 * j + 2];
						//SaveFile1 << (int)prt[3 * j] << " " << (int)prt[3 * j + 1] << " " << (int)prt[3 * j + 2] <<endl;
					}
					//SaveFile1 << endl<<endl<<endl<<endl;
				}
				//SaveFile1 << endl<<endl<<endl<<endl<<endl<<endl<<endl<<endl<<endl<<endl;
				//SaveFile1.close();
				imshow("colorImage", image_rgb);
				//解除锁定
				pTexture->UnlockRect(0);
				
				//释放帧
				m_pNuiSensor->NuiImageStreamReleaseFrame(colorStreamHandle, &pImageFrame_rgb);
			}
			else
			{
				cout << "Buffer length of received texture is bogus\r\n" << endl;
			}
			
			BOOL nearMode;
			INuiFrameTexture* pColorToDepthTexture;


			//深度图像的处理
			if (WaitForSingleObject(nextDepthFrameEvent, INFINITE) == 0)
			{

				hr = m_pNuiSensor->NuiImageStreamGetNextFrame(depthStreamHandle, 0, &pImageFrame_depth);

				if (FAILED(hr))
				{
					cout << "Could not get color image" << endl;
					NuiShutdown();
					return -1;
				}

				hr = m_pNuiSensor->NuiImageFrameGetDepthImagePixelFrameTexture(
					depthStreamHandle, &pImageFrame_depth, &nearMode, &pColorToDepthTexture);
				INuiFrameTexture *pTexture = pImageFrame_depth.pFrameTexture;
				NUI_LOCKED_RECT lockedRect;
				NUI_LOCKED_RECT ColorToDepthLockRect;

				pTexture->LockRect(0, &lockedRect, NULL, 0);
				pColorToDepthTexture->LockRect(0, &ColorToDepthLockRect, NULL, 0);

				//归一化
				for (int i = 0; i < image_depth.rows; i++)
				{
					uchar *prt = image_depth.ptr<uchar>(i);

					uchar* pBuffer = (uchar*)(lockedRect.pBits) + i * lockedRect.Pitch;
					//这里需要转换，因为每个深度数据是2个字节，应将BYTE转成USHORT
					USHORT *pBufferRun = (USHORT*)pBuffer;

					for (int j = 0; j < image_depth.cols; j++)
					{
						//先向，将数据归一化处理，对深度距离在300mm-3500mm范围内的像素，映射到【0—255】内，
						//超出范围的，都去做是边缘像素
						if (pBufferRun[j] << 3 > MAX_DISTANCE) prt[j] = 255;
						else if (pBufferRun[j] << 3 < MIN_DISTANCE) prt[j] = 0;
						else prt[j] = (BYTE)(256 * (pBufferRun[j] << 3) / MAX_DISTANCE);
					}
				}
				imshow("depth", image_depth);



				//接下来是对齐部分，将前景抠出来

				//存放深度点的参数

				NUI_DEPTH_IMAGE_POINT* depthPoints = new NUI_DEPTH_IMAGE_POINT[640 * 480];
				if (ColorToDepthLockRect.Pitch != 0)
				{
					HRESULT hrState = S_OK;

					//一个能在不同空间坐标转变的类（包括：深度，彩色，骨骼）
					INuiCoordinateMapper* pMapper;

					//设置KINECT实例的空间坐标系
					hrState = m_pNuiSensor->NuiGetCoordinateMapper(&pMapper);

					if (FAILED(hrState))
					{
						return hrState;
					}

					//重要的一步：从颜色空间映射到深度空间。参数说明：
					//【参数1】：彩色图像的类型
					//【参数2】：彩色图像的分辨率
					//【参数3】：深度图像的分辨率
					//【参数4】：深度图像的个数
					//【参数5】：深度像素点数
					//【参数6】：取内存的大小，个数。类型为NUI_DEPTH_IMAGE_PIXEL
					//【参数7】：存放映射结果点的参数
					hrState = pMapper->MapColorFrameToDepthFrame(NUI_IMAGE_TYPE_COLOR, NUI_IMAGE_RESOLUTION_640x480, NUI_IMAGE_RESOLUTION_640x480,
						640 * 480, (NUI_DEPTH_IMAGE_PIXEL*)ColorToDepthLockRect.pBits, 640 * 480, depthPoints);

					if (FAILED(hrState))
					{
						return hrState;
					}


					//显示的图像
					Mat show;
					show.create(480, 640, CV_8UC3);
					show = 0;
					int cnt = 0;
					for (int i = 0; i < image_rgb.rows; i++)//480
					{
						for (int j = 0; j < image_rgb.cols; j++)//640
						{
							uchar *prt_rgb = image_rgb.ptr(i);
							uchar *prt_show = show.ptr(i);
							//在内存中偏移量
							long index = i * 640 + j;
							//从保存了映射坐标的数组中获取点
							NUI_DEPTH_IMAGE_POINT depthPointAtIndex = depthPoints[index];

							//边界判断
							if (depthPointAtIndex.x >= 0 && depthPointAtIndex.x < image_depth.cols &&
								depthPointAtIndex.y >= 0 && depthPointAtIndex.y < image_depth.rows)
							{
								//深度判断，在MIN_DISTANCE与MAX_DISTANCE之间的当成前景，显示出来
								//这个使用也很重要，当使用真正的深度像素点再在深度图像中获取深度值来判断的时候，会出错
								if (depthPointAtIndex.depth >= MIN_DISTANCE && depthPointAtIndex.depth <= MAX_DISTANCE)
								{
									prt_show[3 * j] = prt_rgb[j * 3];
									prt_show[3 * j + 1] = prt_rgb[j * 3 + 1];
									prt_show[3 * j + 2] = prt_rgb[j * 3 + 2];
									//SaveFile2 << (int)prt_show[3 * j] << " " << (int)prt_show[3 * j + 1] << " " << (int)prt_show[3 * j + 2] << endl;
								}
							}
						}
					}
					//SaveFile2.close();
					imshow("show", show);
					
				}

				delete[]depthPoints;

				pTexture->UnlockRect(0);
				m_pNuiSensor->NuiImageStreamReleaseFrame(depthStreamHandle, &pImageFrame_depth);
			}

			else
			{
				cout << "Buffer length of received texture is bogus\r\n" << endl;
			}
		}
		
		if (cvWaitKey(20) == 27)
			break;
	}
	return 0;
}


#include <stdio.h>
#include <Kinect10.h>
#include <windows.h>
#include <highgui.h>
#include <cv.h>

using namespace cv;

// 转换depth图像到cv::Mat
Mat ConvertMat(const UINT16* pBuffer, int nWidth, int nHeight)
{
	Mat img(nHeight, nWidth, CV_8UC1);
	uchar* p_mat = img.data;//指向头指针

	const UINT16* pBufferEnd = pBuffer + (nWidth * nHeight);//指向最后一个元素的指针

	while (pBuffer < pBufferEnd)//16位最大值为65536
	{
		*p_mat++ = *pBuffer++ / 65536.0 * 256;
	}
	return img;
}
int main()
{
	IKinectSensor*          m_pKinectSensor;
	IDepthFrameReader*      m_pDepthFrameReader;
	IDepthFrame* pDepthFrame = NULL;
	IFrameDescription* pFrameDescription = NULL;
	IDepthFrameSource* pDepthFrameSource = NULL;

	HRESULT hr = GetDefaultKinectSensor(&m_pKinectSensor);//获取默认kinect传感器
	assert(hr >= 0);
	printf("打开kinect传感器成功\n");

	hr = m_pKinectSensor->Open();//打开传感器
	assert(hr >= 0);
	hr = m_pKinectSensor->get_DepthFrameSource(&pDepthFrameSource);//获得深度信息传感器
	assert(hr >= 0);
	hr = pDepthFrameSource->OpenReader(&m_pDepthFrameReader);//打开深度信息帧读取器
	assert(hr >= 0);

	while (hr < 0 || pDepthFrame == NULL)
		hr = m_pDepthFrameReader->AcquireLatestFrame(&pDepthFrame);//由于有时候获取不到，因此循环获取最近的帧

	assert(hr >= 0);
	hr = pDepthFrame->get_FrameDescription(&pFrameDescription);//获取帧的像素信息（宽和高）
	int depth_width, depth_height;
	pFrameDescription->get_Width(&depth_width);
	pFrameDescription->get_Height(&depth_height);
	printf("width=%d height=%d\n", depth_width, depth_height);

	USHORT nDepthMinReliableDistance = 0;//获取最大、最小深度距离信息
	USHORT nDepthMaxReliableDistance = 0;
	assert(hr >= 0);
	hr = pDepthFrame->get_DepthMinReliableDistance(&nDepthMinReliableDistance);
	assert(hr >= 0);
	hr = pDepthFrame->get_DepthMaxReliableDistance(&nDepthMaxReliableDistance);

	printf("nDepthMinReliableDistance=%d nDepthMaxReliableDistance=%d\n", nDepthMinReliableDistance, nDepthMaxReliableDistance);

	UINT nBufferSize_depth = 0;
	UINT16 *pBuffer_depth = NULL;
	pDepthFrame->AccessUnderlyingBuffer(&nBufferSize_depth, &pBuffer_depth);//获取图像像素个数和指向图像的指针


	//转换为MAT格式
	Mat depthImg_show = ConvertMat(pBuffer_depth, depth_width, depth_height);//转换为8位的mat


	equalizeHist(depthImg_show, depthImg_show);//均衡化，为了提高显示效果

	imwrite("MyFirstKinectImg.jpg", depthImg_show);//保存图片
	//用opencv显示

	namedWindow("display");

	imshow("display", depthImg_show);

	if (27 == waitKey(0))
		return 0;
}+

PCL 
简介http://www.pclcn.org/study/shownews.php?lang=cn&id=29
