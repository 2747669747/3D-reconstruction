//形成深度图像和彩色图像并保存为jpg格式
#include <stdlib.h>
#include <iostream>
#include <string>
//#include "OpenNI.h"
#include "opencv2/core/core.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include "Windows.h"
#include <Shlobj.h>
#include "NuiApi.h"
#include <sstream>


#include <opencv2/opencv.hpp>  

using namespace std;
using namespace cv;
//using namespace openni;


int frameNo = 1;

int main(int argc, char *argv[])
{
	Mat colorImage;
	Mat depthImage;
	colorImage.create(480, 640, CV_8UC3);
	depthImage.create(480, 640, CV_8UC1);

	//1、初始化NUI 
	HRESULT hr = NuiInitialize(NUI_INITIALIZE_FLAG_USES_COLOR | NUI_INITIALIZE_FLAG_USES_DEPTH);
	if (FAILED(hr))
	{
		cout << "NuiInitialize failed" << endl;
		return hr;
	}

	//2、定义事件句柄 
	//创建读取下一帧的信号事件句柄，控制KINECT是否可以开始读取下一帧数据
	HANDLE nextColorFrameEvent = CreateEvent(NULL, TRUE, FALSE, NULL);
	HANDLE colorStreamHandle = NULL; //保存彩色图像数据流的句柄，用以提取数据

	HANDLE nextDepthFrameEvent = CreateEvent(NULL, TRUE, FALSE, NULL);
	HANDLE depthStreamHandle = NULL;//保存深度图像数据流的句柄，用以提取数据

	//3、打开KINECT设备的彩色图信息通道，并用colorStreamHandle保存该流的句柄，以便于以后读取
	hr = NuiImageStreamOpen(NUI_IMAGE_TYPE_COLOR, NUI_IMAGE_RESOLUTION_640x480,
		0, 2, nextColorFrameEvent, &colorStreamHandle);
	if (FAILED(hr))//判断是否提取正确 
	{
		cout << "Could not open color image stream video" << endl;
		NuiShutdown();
		return hr;
	}
	namedWindow("colorImage", CV_WINDOW_AUTOSIZE);

	hr = NuiImageStreamOpen(NUI_IMAGE_TYPE_DEPTH, NUI_IMAGE_RESOLUTION_640x480,
		0, 2, nextDepthFrameEvent, &depthStreamHandle);
	if (FAILED(hr))//判断是否提取正确
	{
		cout << "Could not open depth image stream video" << endl;
		NuiShutdown();
		return hr;
	}
	namedWindow("depthImage", CV_WINDOW_AUTOSIZE);

	//4、开始读取彩色图数据 
	while (1)
	{
		const NUI_IMAGE_FRAME * pColorImageFrame = NULL;
		const NUI_IMAGE_FRAME * pDepthImageFrame = NULL;

		string colorPathPrefix = "colorImage";
		string depthPathPrefix = "depthImage";
		string commonPathSuffix = ".jpg";

		//4.1、无限等待新的彩色图像数据，等到后返回
		if (WaitForSingleObject(nextColorFrameEvent, INFINITE) == 0)
		{

			stringstream ss;
			ss << colorPathPrefix;
			ss << frameNo;
			ss << commonPathSuffix;
			string colorImagePath = ss.str();

			//4.2、从刚才打开数据流的流句柄中得到该帧数据，读取到的数据地址存于pColorImageFrame
			hr = NuiImageStreamGetNextFrame(colorStreamHandle, 0, &pColorImageFrame);
			if (FAILED(hr))
			{
				cout << "Could not get color image" << endl;
				NuiShutdown();
				return -1;
			}

			INuiFrameTexture * pTexture = pColorImageFrame->pFrameTexture;
			NUI_LOCKED_RECT LockedRect;

			//4.3、提取数据帧到LockedRect，它包括两个数据对象：pitch每行字节数，pBits第一个字节地址
			//并锁定数据，这样当我们读数据的时候，kinect就不会去修改它
			pTexture->LockRect(0, &LockedRect, NULL, 0);
			//4.4、确认获得的数据是否有效
			if (LockedRect.Pitch != 0)
			{
				//4.5、将数据转换为OpenCV的Mat格式
				for (int i = 0; i<colorImage.rows; i++)
				{
					uchar *ptr = colorImage.ptr<uchar>(i);  //第i行的指针

					//每个字节代表一个颜色信息，直接使用uchar
					uchar *pBuffer = (uchar*)(LockedRect.pBits) + i * LockedRect.Pitch;
					for (int j = 0; j<colorImage.cols; j++)
					{
						ptr[3 * j] = pBuffer[4 * j];  //内部数据是4个字节，0-1-2是BGR，第4个现在未使用 
						ptr[3 * j + 1] = pBuffer[4 * j + 1];
						ptr[3 * j + 2] = pBuffer[4 * j + 2];
					}
				}
				imwrite(colorImagePath, colorImage);
				imshow("colorImage", colorImage); //显示图像 
			}
			else
			{
				cout << "Buffer length of received texture is bogus\r\n" << endl;
			}

			//5、这帧已经处理完了，所以将其解锁
			pTexture->UnlockRect(0);
			//6、释放本帧数据，准备迎接下一帧 
			NuiImageStreamReleaseFrame(colorStreamHandle, pColorImageFrame);
		}

		//7.1、无限等待新的深度数据，等到后返回
		if (WaitForSingleObject(nextDepthFrameEvent, INFINITE) == 0)
		{
			stringstream ss;
			ss << depthPathPrefix;
			ss << frameNo;
			ss << commonPathSuffix;
			string depthImagePath = ss.str();
			frameNo++;
			//7.2、从刚才打开数据流的流句柄中得到该帧数据，读取到的数据地址存于pImageFrame
			hr = NuiImageStreamGetNextFrame(depthStreamHandle, 0, &pDepthImageFrame);
			if (FAILED(hr))
			{
				cout << "Could not get color image" << endl;
				NuiShutdown();
				return -1;
			}
			INuiFrameTexture * pTexture = pDepthImageFrame->pFrameTexture;
			NUI_LOCKED_RECT LockedRect;
			//7.3、提取数据帧到LockedRect，它包括两个数据对象：pitch每行字节数，pBits第一个字节地址
			//并锁定数据，这样当我们读数据的时候，kinect就不会去修改它
			pTexture->LockRect(0, &LockedRect, NULL, 0);
			//7.4、确认获得的数据是否有效
			if (LockedRect.Pitch != 0)
			{

				//7.5、将数据转换为OpenCV的Mat格式
				for (int i = 0; i<depthImage.rows; i++)
				{
					uchar *ptr = depthImage.ptr(i);  //第i行的指针
					//每个字节代表一个颜色信息，直接使用uchar
					uchar *pBuffer = (uchar*)(LockedRect.pBits) + i * LockedRect.Pitch;
					USHORT *pBufferRun = (USHORT *)pBuffer;//这里需要转换，因为每个深度数据是2个字节，应将BYTE转成USHORT
					for (int j = 0; j<depthImage.cols; j++)
					{
						ptr[j] = 255 - (BYTE)(256 * pBufferRun[j] / 0x1fff); //将数据归一化处理*
					}
				}
				imwrite(depthImagePath, depthImage);
				imshow("depthImage", depthImage); //显示图像

			}
			else
			{
				cout << "Buffer length of received texture is bogus\r\n" << endl;
			}
			//8、这帧已经处理完了，所以将其解锁
			pTexture->UnlockRect(0);
			//9、释放本帧数据，准备迎接下一帧
			NuiImageStreamReleaseFrame(depthStreamHandle, pDepthImageFrame);
			if (frameNo == 10)
				break;
		}

		if (cvWaitKey(20) == 27)
			break;
	}
	//7、关闭NUI链接 
	NuiShutdown();
	return 0;
}
//遇到问题：error C2589: “(”:“::”右边的非法标记
//解决：找到问题所在位置，使用std::min或者std::max的时候加上括号，避免与Windows.h中的min、max宏定义冲突。

将jpg图片用画图工具打开，另存为png格式
读取png图片数据形成点云  参考网站http://blog.csdn.net/u012700322/article/details/51821249，需要在工程文件夹下新建data文件夹，将
深度图片改名为dpeth，彩色图片改名为rgb,形成名为pointcloud的点云图
// C++ 标准库
#include <iostream>
#include <string>
using namespace std;

// OpenCV 库
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>

// PCL 库
#include <pcl/io/pcd_io.h>
#include <pcl/point_types.h>

// 定义点云类型
typedef pcl::PointXYZRGBA PointT;
typedef pcl::PointCloud<PointT> PointCloud; 

// 相机内参
const double camera_factor = 1000;
const double camera_cx = 325.5;
const double camera_cy = 253.5;
const double camera_fx = 518.0;
const double camera_fy = 519.0;

// 主函数 
int main( int argc, char** argv )
{
    // 读取./data/rgb.png和./data/depth.png，并转化为点云

    // 图像矩阵
    cv::Mat rgb, depth;
    // 使用cv::imread()来读取图像
    // API: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html?highlight=imread#cv2.imread
    rgb = cv::imread( "./data/rgb.png" );
    // rgb 图像是8UC3的彩色图像
    // depth 是16UC1的单通道图像，注意flags设置-1,表示读取原始数据不做任何修改
    depth = cv::imread( "./data/depth.png", -1 );

    // 点云变量
    // 使用智能指针，创建一个空点云。这种指针用完会自动释放。
    PointCloud::Ptr cloud ( new PointCloud );
    // 遍历深度图
    for (int m = 0; m < depth.rows; m++)
        for (int n=0; n < depth.cols; n++)
        {
            // 获取深度图中(m,n)处的值
            ushort d = depth.ptr<ushort>(m)[n];
            // d 可能没有值，若如此，跳过此点
            if (d == 0)
                continue;
            // d 存在值，则向点云增加一个点
            PointT p;

            // 计算这个点的空间坐标
            p.z = double(d) / camera_factor;
            p.x = (n - camera_cx) * p.z / camera_fx;
            p.y = (m - camera_cy) * p.z / camera_fy;
            
            // 从rgb图像中获取它的颜色
            // rgb是三通道的BGR格式图，所以按下面的顺序获取颜色
            p.b = rgb.ptr<uchar>(m)[n*3];
            p.g = rgb.ptr<uchar>(m)[n*3+1];
            p.r = rgb.ptr<uchar>(m)[n*3+2];

            // 把p加入到点云中
            cloud->points.push_back( p );
        }
    // 设置并保存点云
    cloud->height = 1;
    cloud->width = cloud->points.size();
    cout<<"point cloud size = "<<cloud->points.size()<<endl;
    cloud->is_dense = false;
    pcl::io::savePCDFile( "./data/pointcloud.pcd", *cloud );
    // 清除数据并退出
    cloud->points.clear();
    cout<<"Point cloud saved."<<endl;
    return 0;
}
 
读取点云数据，形成图样  参考网站：http://blog.csdn.net/jinshengtao/article/details/48917263
需要将pointcloud改名为test_pcd，然后出现后绿黑三个颜色块，需要滚动鼠标，并不断调整鼠标的位置，要使三个轴出现在视野中，最终能够出现点云图
备注：这个网站也附上了形成jpg和depth的代码，但是图像可能没有上一个清晰，注意那个需要点击colorimage的图片再按c键才能存点云图

#include <pcl/visualization/cloud_viewer.h>
#include <iostream>
#include <pcl/io/io.h>
#include <pcl/io/pcd_io.h>
    
int main ()
{
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud (new pcl::PointCloud<pcl::PointXYZRGB>);

	if(pcl::io::loadPCDFile<pcl::PointXYZRGB>("test_pcda.pcd",*cloud)==-1)//*打开点云文件
	{
		PCL_ERROR("Couldn't read file test_pcd.pcd\n");
		return(-1);
	}
	std::cout<<"Loaded "<<cloud->width*cloud->height<<" data points from test_pcd.pcd with the following fields: "<<std::endl;

	pcl::visualization::CloudViewer viewer("My First Cloud Viewer");
	viewer.showCloud(cloud);
	while(!viewer.wasStopped())
	{

	}
}

基于ICP算法实现的三维重建 参考网站：http://blog.csdn.net/jinshengtao/article/details/48917263
                                 http://blog.csdn.net/qq_33933704/article/details/78652633
这里我用的是前一种，需要形成三个点云图，分别命名为test_pcda,test_pcdb,test_pcdc
#include <iostream>
#include <pcl/io/pcd_io.h>
#include <pcl/point_types.h>
#include <pcl/registration/icp.h>
#include <pcl/visualization/cloud_viewer.h>
#include <pcl/kdtree/kdtree_flann.h>
#include <time.h>

int  main(int argc, char** argv)
{
	clock_t start, finish;
	double totaltime;


	pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud_in(new pcl::PointCloud<pcl::PointXYZRGB>);
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud_out(new pcl::PointCloud<pcl::PointXYZRGB>);
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud_out2(new pcl::PointCloud<pcl::PointXYZRGB>);
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr my_cloud(new pcl::PointCloud<pcl::PointXYZRGB>);
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr my_cloud2(new pcl::PointCloud<pcl::PointXYZRGB>);

	start = clock();
	if (pcl::io::loadPCDFile<pcl::PointXYZRGB>("pointcloud.pcd", *cloud_in) == -1)//*打开点云文件
	{
		PCL_ERROR("Couldn't read file test_pcd.pcd\n");
		return(-1);
	}
	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n load test_pcda.pcd data : " << totaltime << "seconds!" << endl;

	start = clock();
	if (pcl::io::loadPCDFile<pcl::PointXYZRGB>("test_pcdb.pcd", *cloud_out) == -1)//*打开点云文件
	{
		PCL_ERROR("Couldn't read file test_pcd.pcd\n");
		return(-1);
	}
	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n load test_pcdb.pcd data : " << totaltime << "seconds!" << endl;

	start = clock();
	if (pcl::io::loadPCDFile<pcl::PointXYZRGB>("test_pcdc.pcd", *cloud_out2) == -1)//*打开点云文件
	{
		PCL_ERROR("Couldn't read file test_pcd.pcd\n");
		return(-1);
	}
	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n load test_pcdc.pcd data : " << totaltime << "seconds!" << endl;

	//call icp api
	start = clock();
	pcl::IterativeClosestPoint<pcl::PointXYZRGB, pcl::PointXYZRGB> icp;
	icp.setInputSource(cloud_in);
	icp.setInputTarget(cloud_out);
	pcl::PointCloud<pcl::PointXYZRGB> Final;
	icp.align(Final);
	std::cout << "has converged:" << icp.hasConverged() << " score: " <<
		icp.getFitnessScore() << std::endl;
	std::cout << icp.getFinalTransformation() << std::endl;

	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n first time call icp process : " << totaltime << "seconds!" << endl;

	//构造拼接临时的点云
	for (int i = 0; i< Final.points.size(); i++)
	{
		pcl::PointXYZRGB basic_point;
		basic_point.x = Final.points[i].x;
		basic_point.y = Final.points[i].y;
		basic_point.z = Final.points[i].z;
		basic_point.r = Final.points[i].r;
		basic_point.g = Final.points[i].g;
		basic_point.b = Final.points[i].b;
		my_cloud->points.push_back(basic_point);
	}

	//call icp api another time
	start = clock();
	icp.setInputSource(cloud_out2);
	icp.setInputTarget(my_cloud);
	pcl::PointCloud<pcl::PointXYZRGB> Final2;
	icp.align(Final2);
	std::cout << "has converged:" << icp.hasConverged() << " score: " <<
		icp.getFitnessScore() << std::endl;
	std::cout << icp.getFinalTransformation() << std::endl;
	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n second time call icp process : " << totaltime << "seconds!" << endl;

	//my_cloud.reset();
	//构造拼接最终的点云
	for (int i = 0; i< Final2.points.size(); i++)
	{
		pcl::PointXYZRGB basic_point;
		basic_point.x = Final2.points[i].x;
		basic_point.y = Final2.points[i].y;
		basic_point.z = Final2.points[i].z;
		basic_point.r = Final2.points[i].r;
		basic_point.g = Final2.points[i].g;
		basic_point.b = Final2.points[i].b;
		my_cloud2->points.push_back(basic_point);
	}

	pcl::visualization::CloudViewer viewer("My First Cloud Viewer");
	viewer.showCloud(my_cloud2);
	while (!viewer.wasStopped())
	{

	}
	return (0);
}
