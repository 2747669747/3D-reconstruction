#include <pcl/io/pcd_io.h>
#include <pcl/point_types.h>
// 标准库头文件
#include <iostream>
#include <string>
#include <vector> 
// OpenCV头文件
#include <opencv2\core\core.hpp>
#include <opencv2\highgui\highgui.hpp>
#include <opencv2\imgproc\imgproc.hpp> 
// OpenNI头文件
#include <OpenNI.h> 
typedef unsigned char uint8_t;
// namespace
using namespace std;
using namespace openni;
using namespace cv;
using namespace pcl;

void CheckOpenNIError(Status result, string status)
{
	if (result != STATUS_OK)
		cerr << status << " Error: " << OpenNI::getExtendedError() << endl;
}

int main(int argc, char **argv)
{
	Status result = STATUS_OK;
	int i, j;
	float x = 0.0, y = 0.0, z = 0.0, xx = 0.0;
	//IplImage *test,*test2;
	IplImage *test2;

	//point cloud 
	PointCloud<PointXYZRGB> cloud;

	//opencv image
	Mat cvBGRImg;
	Mat cvDepthImg;

	//OpenNI2 image  
	VideoFrameRef oniDepthImg;
	VideoFrameRef oniColorImg;

	namedWindow("depth");
	namedWindow("image");

	char key = 0;

	// 初始化OpenNI  
	result = OpenNI::initialize();
	CheckOpenNIError(result, "initialize context");

	// open device    
	Device device;
	result = device.open(openni::ANY_DEVICE);
	CheckOpenNIError(result, "open device");


	// create depth stream   
	VideoStream oniDepthStream;
	result = oniDepthStream.create(device, openni::SENSOR_DEPTH);
	CheckOpenNIError(result, "create depth stream");

	// set depth video mode  
	VideoMode modeDepth;
	modeDepth.setResolution(640, 480);
	modeDepth.setFps(30);
	modeDepth.setPixelFormat(PIXEL_FORMAT_DEPTH_1_MM);
	oniDepthStream.setVideoMode(modeDepth);
	// start depth stream  
	result = oniDepthStream.start();
	CheckOpenNIError(result, "start depth stream");

	// create color stream  
	VideoStream oniColorStream;
	result = oniColorStream.create(device, openni::SENSOR_COLOR);
	CheckOpenNIError(result, "create color stream");
	// set color video mode  
	VideoMode modeColor;
	modeColor.setResolution(640, 480);
	modeColor.setFps(30);
	modeColor.setPixelFormat(PIXEL_FORMAT_RGB888);
	oniColorStream.setVideoMode(modeColor);
	// start color stream  
	result = oniColorStream.start();
	CheckOpenNIError(result, "start color stream");
	int cnt = 0;
	while (true)
	{
		// read frame  
		if (oniColorStream.readFrame(&oniColorImg) == STATUS_OK)
		{
			// convert data into OpenCV type  
			Mat cvRGBImg(oniColorImg.getHeight(), oniColorImg.getWidth(), CV_8UC3, (void*)oniColorImg.getData());
			cvtColor(cvRGBImg, cvBGRImg, CV_RGB2BGR);
			imshow("image", cvBGRImg);
		}

		if (oniDepthStream.readFrame(&oniDepthImg) == STATUS_OK)
		{
			Mat cvRawImg16U(oniDepthImg.getHeight(), oniDepthImg.getWidth(), CV_16UC1, (void*)oniDepthImg.getData());
			cvRawImg16U.convertTo(cvDepthImg, CV_8U, 255.0 / (oniDepthStream.getMaxPixelValue()));
			imshow("depth", cvDepthImg);
		}
		// quit
		if (cv::waitKey(1) == 'q')
			break;
		// capture  depth and color data   
		if (cv::waitKey(1) == 'c')
		{
			//get data
			DepthPixel *pDepth = (DepthPixel*)oniDepthImg.getData();
			//create point cloud
			cloud.width = oniDepthImg.getWidth();
			cloud.height = oniDepthImg.getHeight();
			cloud.is_dense = false;
			cloud.points.resize(cloud.width * cloud.height);
			//test = cvCreateImage(cvSize(cloud.width,cloud.height),IPL_DEPTH_8U,3);
			test2 = &IplImage(cvBGRImg);

			for (i = 0; i<oniDepthImg.getHeight(); i++)
			{
				for (j = 0; j<oniDepthImg.getWidth(); j++)
				{
					float k = i;
					float m = j;
					xx = pDepth[i*oniDepthImg.getWidth() + j];
					CoordinateConverter::convertDepthToWorld(oniDepthStream, m, k, xx, &x, &y, &z);
					cloud[i*cloud.width + j].x = x;
					cloud[i*cloud.width + j].y = y;
					cloud[i*cloud.width + j].z = xx;
					cloud[i*cloud.width + j].b = (uint8_t)test2->imageData[i*test2->widthStep + j * 3 + 0];
					cloud[i*cloud.width + j].g = (uint8_t)test2->imageData[i*test2->widthStep + j * 3 + 1];
					cloud[i*cloud.width + j].r = (uint8_t)test2->imageData[i*test2->widthStep + j * 3 + 2];
					/* test->imageData[i*test->widthStep+j*3+0] = test2->imageData[i*test2->widthStep+j*3+0];
					test->imageData[i*test->widthStep+j*3+1] = test2->imageData[i*test2->widthStep+j*3+1];
					test->imageData[i*test->widthStep+j*3+2] = test2->imageData[i*test2->widthStep+j*3+2];*/
				}
			}
			if (cnt % 3 == 0)
			{
				pcl::io::savePCDFileBinaryCompressed("test_pcda.pcd", cloud);
				cerr << "Saved " << cloud.points.size() << " data points to test_pcda.pcd." << endl;
				imwrite("a_color.jpg", cvBGRImg);
				imwrite("a_depth.jpg", cvDepthImg);
			}
			else if (cnt % 3 == 1)
			{
				pcl::io::savePCDFileBinaryCompressed("test_pcdb.pcd", cloud);
				cerr << "Saved " << cloud.points.size() << " data points to test_pcdb.pcd." << endl;
				imwrite("b_color.jpg", cvBGRImg);
				imwrite("b_depth.jpg", cvDepthImg);
			}
			else if (cnt % 3 == 2)
			{
				pcl::io::savePCDFileBinaryCompressed("test_pcdc.pcd", cloud);
				cerr << "Saved " << cloud.points.size() << " data points to test_pcdc.pcd." << endl;
				imwrite("c_color.jpg", cvBGRImg);
				imwrite("c_depth.jpg", cvDepthImg);
			}
			cnt++;
		}
	}
}
#include <iostream>
#include <string>
using namespace std;

// OpenCV 库
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>

// PCL 库
#include <pcl/io/pcd_io.h>
#include <pcl/point_types.h>

// 定义点云类型
typedef pcl::PointXYZRGBA PointT;
typedef pcl::PointCloud<PointT> PointCloud;

// 相机内参
const double camera_factor = 1000;
const double camera_cx = 325.5;
const double camera_cy = 253.5;
const double camera_fx = 518.0;
const double camera_fy = 519.0;

// 主函数 
int main(int argc, char** argv)
{
	// 图像矩阵
	cv::Mat rgb, depth;
	// 读取./data/rgb.png和./data/depth.png，并转化为点云
	// 使用cv::imread()来读取图像
	// API: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html?highlight=imread#cv2.imread
	for (int i = 1; i <= 3; i++)
	{
		if (i == 1)
		{
			rgb = cv::imread("./data/a_color.png");
			// rgb 图像是8UC3的彩色图像
			// depth 是16UC1的单通道图像，注意flags设置-1,表示读取原始数据不做任何修改
			depth = cv::imread("./data/a_depth.png", -1);

			// 点云变量
			// 使用智能指针，创建一个空点云。这种指针用完会自动释放。
			PointCloud::Ptr cloud(new PointCloud);
			// 遍历深度图
			for (int m = 0; m < depth.rows; m++)
				for (int n = 0; n < depth.cols; n++)
				{
					// 获取深度图中(m,n)处的值
					ushort d = depth.ptr<ushort>(m)[n];
					// d 可能没有值，若如此，跳过此点
					if (d == 0)
						continue;
					// d 存在值，则向点云增加一个点
					PointT p;

					// 计算这个点的空间坐标
					p.z = double(d) / camera_factor;
					p.x = (n - camera_cx) * p.z / camera_fx;
					p.y = (m - camera_cy) * p.z / camera_fy;

					// 从rgb图像中获取它的颜色
					// rgb是三通道的BGR格式图，所以按下面的顺序获取颜色
					p.b = rgb.ptr<uchar>(m)[n * 3];
					p.g = rgb.ptr<uchar>(m)[n * 3 + 1];
					p.r = rgb.ptr<uchar>(m)[n * 3 + 2];

					// 把p加入到点云中
					cloud->points.push_back(p);
				}
			// 设置并保存点云
			cloud->height = 1;
			cloud->width = cloud->points.size();
			cout << "point clouda size = " << cloud->points.size() << endl;
			cloud->is_dense = false;
			pcl::io::savePCDFile("./data/pointclouda.pcd", *cloud);
			// 清除数据并退出
			cloud->points.clear();
			cout << "Point clouda saved." << endl;
		}
		else if (i == 2)
		{
			rgb = cv::imread("./data/b_color.png");
			// rgb 图像是8UC3的彩色图像
			// depth 是16UC1的单通道图像，注意flags设置-1,表示读取原始数据不做任何修改
			depth = cv::imread("./data/b_depth.png", -1);

			// 点云变量
			// 使用智能指针，创建一个空点云。这种指针用完会自动释放。
			PointCloud::Ptr cloud(new PointCloud);
			// 遍历深度图
			for (int m = 0; m < depth.rows; m++)
				for (int n = 0; n < depth.cols; n++)
				{
					// 获取深度图中(m,n)处的值
					ushort d = depth.ptr<ushort>(m)[n];
					// d 可能没有值，若如此，跳过此点
					if (d == 0)
						continue;
					// d 存在值，则向点云增加一个点
					PointT p;

					// 计算这个点的空间坐标
					p.z = double(d) / camera_factor;
					p.x = (n - camera_cx) * p.z / camera_fx;
					p.y = (m - camera_cy) * p.z / camera_fy;

					// 从rgb图像中获取它的颜色
					// rgb是三通道的BGR格式图，所以按下面的顺序获取颜色
					p.b = rgb.ptr<uchar>(m)[n * 3];
					p.g = rgb.ptr<uchar>(m)[n * 3 + 1];
					p.r = rgb.ptr<uchar>(m)[n * 3 + 2];

					// 把p加入到点云中
					cloud->points.push_back(p);
				}
			// 设置并保存点云
			cloud->height = 1;
			cloud->width = cloud->points.size();
			cout << "point cloudb size = " << cloud->points.size() << endl;
			cloud->is_dense = false;
			pcl::io::savePCDFile("./data/pointcloudb.pcd", *cloud);
			// 清除数据并退出
			cloud->points.clear();
			cout << "Point cloudb saved." << endl;
		}
		else
		{
			// 图像矩阵
			cv::Mat rgb, depth;
			// 使用cv::imread()来读取图像
			// API: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html?highlight=imread#cv2.imread
			rgb = cv::imread("./data/c_color.png");
			// rgb 图像是8UC3的彩色图像
			// depth 是16UC1的单通道图像，注意flags设置-1,表示读取原始数据不做任何修改
			depth = cv::imread("./data/c_depth.png", -1);

			// 点云变量
			// 使用智能指针，创建一个空点云。这种指针用完会自动释放。
			PointCloud::Ptr cloud(new PointCloud);
			// 遍历深度图
			for (int m = 0; m < depth.rows; m++)
				for (int n = 0; n < depth.cols; n++)
				{
					// 获取深度图中(m,n)处的值
					ushort d = depth.ptr<ushort>(m)[n];
					// d 可能没有值，若如此，跳过此点
					if (d == 0)
						continue;
					// d 存在值，则向点云增加一个点
					PointT p;

					// 计算这个点的空间坐标
					p.z = double(d) / camera_factor;
					p.x = (n - camera_cx) * p.z / camera_fx;
					p.y = (m - camera_cy) * p.z / camera_fy;

					// 从rgb图像中获取它的颜色
					// rgb是三通道的BGR格式图，所以按下面的顺序获取颜色
					p.b = rgb.ptr<uchar>(m)[n * 3];
					p.g = rgb.ptr<uchar>(m)[n * 3 + 1];
					p.r = rgb.ptr<uchar>(m)[n * 3 + 2];

					// 把p加入到点云中
					cloud->points.push_back(p);
				}
			// 设置并保存点云
			cloud->height = 1;
			cloud->width = cloud->points.size();
			cout << "point cloudc size = " << cloud->points.size() << endl;
			cloud->is_dense = false;
			pcl::io::savePCDFile("./data/pointcloudc.pcd", *cloud);
			// 清除数据并退出
			cloud->points.clear();
			cout << "Point cloudc saved." << endl;
		}
	}
	return 0;
}

#include <iostream>
#include <pcl/io/pcd_io.h>
#include <pcl/point_types.h>
#include <pcl/registration/icp.h>
#include <pcl/visualization/cloud_viewer.h>
#include <pcl/kdtree/kdtree_flann.h>
#include <time.h>

int  main(int argc, char** argv)
{
	clock_t start, finish;
	double totaltime;


	pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud_in(new pcl::PointCloud<pcl::PointXYZRGB>);
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud_out(new pcl::PointCloud<pcl::PointXYZRGB>);
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud_out2(new pcl::PointCloud<pcl::PointXYZRGB>);
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr my_cloud(new pcl::PointCloud<pcl::PointXYZRGB>);
	pcl::PointCloud<pcl::PointXYZRGB>::Ptr my_cloud2(new pcl::PointCloud<pcl::PointXYZRGB>);

	start = clock();
	if (pcl::io::loadPCDFile<pcl::PointXYZRGB>("./data/pointclouda.pcd", *cloud_in) == -1)//*打开点云文件
	{
		PCL_ERROR("Couldn't read file pointclouda.pcd\n");
		return(-1);
	}
	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n load pointclouda.pcd data : " << totaltime << "seconds!" << endl;

	start = clock();
	if (pcl::io::loadPCDFile<pcl::PointXYZRGB>("./data/pointcloudb.pcd", *cloud_out) == -1)//*打开点云文件
	{
		PCL_ERROR("Couldn't read file pointcloudb.pcd\n");
		return(-1);
	}
	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n load pointcloudb.pcd data : " << totaltime << "seconds!" << endl;

	start = clock();
	if (pcl::io::loadPCDFile<pcl::PointXYZRGB>("./data/pointcloudc.pcd", *cloud_out2) == -1)//*打开点云文件
	{
		PCL_ERROR("Couldn't read file pointcloudc.pcd\n");
		return(-1);
	}
	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n load pointcloudc.pcd data : " << totaltime << "seconds!" << endl;

	//call icp api
	start = clock();
	pcl::IterativeClosestPoint<pcl::PointXYZRGB, pcl::PointXYZRGB> icp;
	icp.setInputSource(cloud_in);
	icp.setInputTarget(cloud_out);
	pcl::PointCloud<pcl::PointXYZRGB> Final;
	icp.align(Final);
	std::cout << "has converged:" << icp.hasConverged() << " score: " <<
		icp.getFitnessScore() << std::endl;
	std::cout << icp.getFinalTransformation() << std::endl;

	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n first time call icp process : " << totaltime << "seconds!" << endl;

	//构造拼接临时的点云
	for (int i = 0; i< Final.points.size(); i++)
	{
		pcl::PointXYZRGB basic_point;
		basic_point.x = Final.points[i].x;
		basic_point.y = Final.points[i].y;
		basic_point.z = Final.points[i].z;
		basic_point.r = Final.points[i].r;
		basic_point.g = Final.points[i].g;
		basic_point.b = Final.points[i].b;
		my_cloud->points.push_back(basic_point);
	}

	//call icp api another time
	start = clock();
	icp.setInputSource(cloud_out2);
	icp.setInputTarget(my_cloud);
	pcl::PointCloud<pcl::PointXYZRGB> Final2;
	icp.align(Final2);
	std::cout << "has converged:" << icp.hasConverged() << " score: " <<
		icp.getFitnessScore() << std::endl;
	std::cout << icp.getFinalTransformation() << std::endl;
	finish = clock();
	totaltime = (double)(finish - start) / CLOCKS_PER_SEC;
	cout << "\n second time call icp process : " << totaltime << "seconds!" << endl;

	//my_cloud.reset();
	//构造拼接最终的点云
	for (int i = 0; i< Final2.points.size(); i++)
	{
		pcl::PointXYZRGB basic_point;
		basic_point.x = Final2.points[i].x;
		basic_point.y = Final2.points[i].y;
		basic_point.z = Final2.points[i].z;
		basic_point.r = Final2.points[i].r;
		basic_point.g = Final2.points[i].g;
		basic_point.b = Final2.points[i].b;
		my_cloud2->points.push_back(basic_point);
	}

	pcl::visualization::CloudViewer viewer("My First Cloud Viewer");
	viewer.showCloud(my_cloud2);
	while (!viewer.wasStopped())
	{

	}
	return (0);
}
